{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------\n",
    "# Create Results Directory Structure\n",
    "# ----------------------\n",
    "def create_results_directories():\n",
    "    \"\"\"Create directory structure for storing results\"\"\"\n",
    "    directories = [\n",
    "        'results',\n",
    "        'results/cross_validation',\n",
    "        'results/external_validation',\n",
    "        'results/monte_carlo',\n",
    "        'results/comparison',\n",
    "        'results/train_predictions',\n",
    "        'results/test_predictions'\n",
    "    ]\n",
    "\n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    print(\"Results directory structure created\")\n",
    "\n",
    "# ----------------------\n",
    "# 1. Data Preparation and Preprocessing\n",
    "# ----------------------\n",
    "# Load data\n",
    "merged_df = pd.read_csv('./Train_Test.csv')\n",
    "\n",
    "# Calculate weighted sum\n",
    "weights1 = {'D1': 10, 'D3': 9, 'D2': 9, 'D6': 13, 'D5': 10, 'D4': 14}\n",
    "weights2 = {'D7-1': 5.90, 'D7-7': 3.54, 'D7-2': 5.90, 'D7-5': 4.33, 'D7-8': 3.13, 'D7-3': 3.15, 'D7-4': 5.90, 'D7-6': 3.15}\n",
    "weighted_sum1 = sum(merged_df[feature] * weight for feature, weight in weights1.items())\n",
    "weighted_sum2 = sum(merged_df[feature] * weight for feature, weight in weights2.items())\n",
    "merged_df['target'] = weighted_sum1 + weighted_sum2\n",
    "\n",
    "# Dataset splitting\n",
    "X = merged_df.drop(['cas', 'target'], axis=1).values\n",
    "y = merged_df['target'].values\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------\n",
    "# 2. Model Definitions\n",
    "# ----------------------\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron with dropout for uncertainty estimation\"\"\"\n",
    "    def __init__(self, input_dim, dropout_prob=0.001):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Single dropout layer instance\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout(x)  # Apply dropout after intermediate hidden layers\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        return self.fc6(x)  # No dropout before output layer\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"Self-attention mechanism for capturing feature interactions\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.query = nn.Linear(input_dim, input_dim)\n",
    "        self.key = nn.Linear(input_dim, input_dim)\n",
    "        self.value = nn.Linear(input_dim, input_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        attention_weights = self.softmax(torch.bmm(Q, K.transpose(1, 2)) / (x.shape[2] ** 0.5))\n",
    "        return torch.bmm(attention_weights, V)\n",
    "\n",
    "class MLP_Attention(nn.Module):\n",
    "    \"\"\"MLP with self-attention mechanism and dropout\"\"\"\n",
    "    def __init__(self, input_dim, dropout_prob=0.01):  # Add dropout_prob parameter\n",
    "        super(MLP_Attention, self).__init__()\n",
    "        self.attention = SelfAttention(input_dim)\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Create dropout layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.attention(x)\n",
    "        x = x.squeeze(1)\n",
    "\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        return self.fc6(x)\n",
    "\n",
    "# 1D-CNN Model\n",
    "class CNNModel(nn.Module):\n",
    "    \"\"\"Convolutional Neural Network for tabular data\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1   = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2   = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1   = nn.Linear(128 * (input_dim // 8), 64)\n",
    "        self.dropout = nn.Dropout(0.001)\n",
    "        self.fc2   = nn.Linear(64,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "class CNN_Attention(nn.Module):\n",
    "    \"\"\"1D-CNN with self-attention mechanism\"\"\"\n",
    "    def __init__(self, input_dim):\n",
    "        super(CNN_Attention, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32,\n",
    "                               kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1   = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64,\n",
    "                               kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2   = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128,\n",
    "                               kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3   = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.attention = SelfAttention(128)\n",
    "\n",
    "        self.fc_input_dim = (input_dim // 8) * 128\n",
    "\n",
    "        self.fc1 = nn.Linear(self.fc_input_dim, 64)\n",
    "        self.dropout = nn.Dropout(0.001)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3  = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.pool1(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.attention(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        out = self.fc3(x)\n",
    "        return out\n",
    "\n",
    "class AttentionModel(nn.Module):\n",
    "    \"\"\"Attention-based model for regression\"\"\"\n",
    "    def __init__(self, input_dim, dropout_rate=0.001):\n",
    "        super(AttentionModel, self).__init__()\n",
    "        self.attention = SelfAttention(input_dim)\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.attention(x.unsqueeze(1)).squeeze(1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "# ----------------------\n",
    "# Device Selection\n",
    "# ----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ----------------------\n",
    "# 3. Load External Validation Set\n",
    "# ----------------------\n",
    "def load_external_validation_set(file_path='./External_Validation.csv'):\n",
    "    \"\"\"Load and preprocess external validation dataset\"\"\"\n",
    "    try:\n",
    "        ext_df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded external validation set: {file_path}\")\n",
    "        print(f\"Shape of external validation set: {ext_df.shape}\")\n",
    "\n",
    "        # Calculate weighted sum (same method as training data)\n",
    "        weighted_sum1 = sum(ext_df[feature] * weight for feature, weight in weights1.items())\n",
    "        weighted_sum2 = sum(ext_df[feature] * weight for feature, weight in weights2.items())\n",
    "        ext_df['target'] = weighted_sum1 + weighted_sum2\n",
    "\n",
    "        # Extract features and target\n",
    "        casNumber = ext_df['cas']\n",
    "        X_ext = ext_df.drop(['cas', 'target'], axis=1).values\n",
    "        y_ext = ext_df['target'].values\n",
    "\n",
    "        # Standardize using the same scaler as training data\n",
    "        X_ext_scaled = scaler.transform(X_ext)\n",
    "\n",
    "        return X_ext_scaled, y_ext, casNumber\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading external validation set: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# ----------------------\n",
    "# 4. Monte Carlo Dropout Implementation\n",
    "# ----------------------\n",
    "def monte_carlo_prediction(model, X, n_samples=1000, dropout_prob=0.1):\n",
    "    \"\"\"\n",
    "    Perform prediction using Monte Carlo dropout for uncertainty estimation\n",
    "\n",
    "    Args:\n",
    "    - model: Trained PyTorch model\n",
    "    - X: Input features (numpy array)\n",
    "    - n_samples: Number of Monte Carlo samples\n",
    "    - dropout_prob: Dropout probability\n",
    "\n",
    "    Returns:\n",
    "    - mean_pred: Mean prediction\n",
    "    - std_pred: Standard deviation\n",
    "    - ci_lower: 95% confidence interval lower bound\n",
    "    - ci_upper: 95% confidence interval upper bound\n",
    "    - all_preds: All predictions\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode but keep dropout enabled\n",
    "    model.eval()\n",
    "\n",
    "    # Set dropout probability for all dropout layers in the model\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.p = dropout_prob\n",
    "            m.train()  # Enable dropout even in eval mode\n",
    "\n",
    "    # Convert to PyTorch tensor\n",
    "    X_tensor = torch.FloatTensor(X).to(device)\n",
    "\n",
    "    # Store all predictions\n",
    "    all_preds = []\n",
    "\n",
    "    # Perform multiple predictions\n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            preds = model(X_tensor).cpu().numpy().flatten()\n",
    "            all_preds.append(preds)\n",
    "\n",
    "    # Convert predictions to numpy array [n_samples, n_samples]\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    # Calculate statistics\n",
    "    mean_pred = np.mean(all_preds, axis=0)\n",
    "    std_pred = np.std(all_preds, axis=0)\n",
    "\n",
    "    # Calculate 95% confidence interval\n",
    "    ci_lower = np.percentile(all_preds, 2.5, axis=0)\n",
    "    ci_upper = np.percentile(all_preds, 97.5, axis=0)\n",
    "\n",
    "    return mean_pred, std_pred, ci_lower, ci_upper, all_preds\n",
    "\n",
    "# ----------------------\n",
    "# 5. Modified Cross-Validation Framework\n",
    "# ----------------------\n",
    "def kfold_validate(model_class, X_train_val, y_train_val, n_splits=10, epochs=1500, patience=150, lr=0.001, monte_carlo=True):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using cross-validation, supporting 5-fold and 10-fold validation,\n",
    "    and save results as CSV\n",
    "\n",
    "    Args:\n",
    "    - model_class: Model class\n",
    "    - X_train_val: Training and validation features\n",
    "    - y_train_val: Training and validation targets\n",
    "    - n_splits: Number of folds (5 or 10)\n",
    "    - epochs: Number of training epochs\n",
    "    - patience: Early stopping patience\n",
    "    - lr: Learning rate\n",
    "    - monte_carlo: Whether to use Monte Carlo dropout for uncertainty estimation\n",
    "\n",
    "    Returns:\n",
    "    - metrics: Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    metrics = {'r2': [], 'mae': [], 'mse': []}\n",
    "\n",
    "    if monte_carlo:\n",
    "        metrics.update({'std': [], 'ci_width': []})\n",
    "\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"Validating Model: {model_class.__name__} with {n_splits}-fold Cross Validation\")\n",
    "    print(f\"{'='*90}\")\n",
    "\n",
    "    # Prepare CSV data\n",
    "    csv_data = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val)):\n",
    "        # Data standardization (independent for each fold)\n",
    "        print(f\"\\n{'='*45}\")\n",
    "        print(f\"Fold: {fold+1}/{n_splits}\")\n",
    "        print(f\"{'='*45}\")\n",
    "        X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "        y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "        fold_scaler = StandardScaler()\n",
    "        X_train = fold_scaler.fit_transform(X_train)\n",
    "        X_val = fold_scaler.transform(X_val)\n",
    "\n",
    "        # Convert to tensors and move to GPU\n",
    "        X_train_t = torch.FloatTensor(X_train).to(device)\n",
    "        y_train_t = torch.FloatTensor(y_train).unsqueeze(1).to(device)\n",
    "        X_val_t = torch.FloatTensor(X_val).to(device)\n",
    "        y_val_t = torch.FloatTensor(y_val).unsqueeze(1).to(device)\n",
    "\n",
    "        # Initialize model and move to GPU\n",
    "        model = model_class(X_train.shape[1]).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        wait = 0\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_t)\n",
    "            loss = criterion(outputs, y_train_t)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Validation evaluation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = criterion(model(X_val_t), y_val_t)\n",
    "\n",
    "            # Print every 50 epochs\n",
    "            if (epoch + 1) % 50 == 0 or epoch == 0:\n",
    "                print(f\"[Fold {fold+1}/{n_splits}] Epoch {epoch+1:04d}/{epochs:04d} | \"\n",
    "                      f\"Train Loss: {loss.item():.4f} | \"\n",
    "                      f\"Val Loss: {val_loss.item():.4f} | \"\n",
    "                      f\"Wait: {wait}/{patience}\")\n",
    "\n",
    "            # Early stopping mechanism\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss.item()\n",
    "                wait = 0\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    break\n",
    "\n",
    "        # Record metrics (move results back to CPU)\n",
    "        with torch.no_grad():\n",
    "            preds = model(X_val_t).cpu().numpy().flatten()\n",
    "\n",
    "        # Basic metrics\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mae = mean_absolute_error(y_val, preds)\n",
    "        mse = mean_squared_error(y_val, preds)\n",
    "\n",
    "        metrics['r2'].append(r2)\n",
    "        metrics['mae'].append(mae)\n",
    "        metrics['mse'].append(mse)\n",
    "\n",
    "        # Prepare CSV row data\n",
    "        fold_data = {\n",
    "            'fold_id': fold + 1,\n",
    "            'r2': r2,\n",
    "            'mae': mae,\n",
    "            'mse': mse\n",
    "        }\n",
    "\n",
    "        # Monte Carlo uncertainty estimation\n",
    "        if monte_carlo:\n",
    "            mean_pred, std_pred, ci_lower, ci_upper, _ = monte_carlo_prediction(model, X_val)\n",
    "            mean_std = np.mean(std_pred)\n",
    "            mean_ci_width = np.mean(ci_upper - ci_lower)\n",
    "\n",
    "            metrics['std'].append(mean_std)\n",
    "            metrics['ci_width'].append(mean_ci_width)\n",
    "\n",
    "            # Add Monte Carlo statistics to CSV row\n",
    "            fold_data.update({\n",
    "                'mean_std': mean_std,\n",
    "                'mean_ci_width': mean_ci_width,\n",
    "                'mean_ci_lower': np.mean(ci_lower),\n",
    "                'mean_ci_upper': np.mean(ci_upper)\n",
    "            })\n",
    "\n",
    "            print(f\"\\n📊 Monte Carlo Uncertainty Estimation (Fold {fold+1}/{n_splits}):\")\n",
    "            print(f\"Average Standard Deviation: {mean_std:.4f}\")\n",
    "            print(f\"Average 95% Confidence Interval Width: {mean_ci_width:.4f}\")\n",
    "            print(f\"Mean CI Lower Bound: {np.mean(ci_lower):.4f}\")\n",
    "            print(f\"Mean CI Upper Bound: {np.mean(ci_upper):.4f}\")\n",
    "\n",
    "        # Add to CSV data\n",
    "        csv_data.append(fold_data)\n",
    "\n",
    "    # Calculate and print cross-validation results\n",
    "    print(f\"\\n🔍 {n_splits}-Fold Cross-Validation Results for {model_class.__name__}:\")\n",
    "    print(f\"R²: {np.mean(metrics['r2']):.4f} ± {np.std(metrics['r2']):.4f}\")\n",
    "    print(f\"MAE: {np.mean(metrics['mae']):.4f} ± {np.std(metrics['mae']):.4f}\")\n",
    "    print(f\"MSE: {np.mean(metrics['mse']):.4f} ± {np.std(metrics['mse']):.4f}\")\n",
    "\n",
    "    if monte_carlo:\n",
    "        print(f\"Average Standard Deviation: {np.mean(metrics['std']):.4f}\")\n",
    "        print(f\"Average 95% Confidence Interval Width: {np.mean(metrics['ci_width']):.4f}\")\n",
    "\n",
    "    # Add summary rows\n",
    "    summary_row = {\n",
    "        'fold_id': 'mean',\n",
    "        'r2': np.mean(metrics['r2']),\n",
    "        'mae': np.mean(metrics['mae']),\n",
    "        'mse': np.mean(metrics['mse'])\n",
    "    }\n",
    "\n",
    "    std_row = {\n",
    "        'fold_id': 'std',\n",
    "        'r2': np.std(metrics['r2']),\n",
    "        'mae': np.std(metrics['mae']),\n",
    "        'mse': np.std(metrics['mse'])\n",
    "    }\n",
    "\n",
    "    if monte_carlo:\n",
    "        summary_row.update({\n",
    "            'mean_std': np.mean(metrics['std']),\n",
    "            'mean_ci_width': np.mean(metrics['ci_width'])\n",
    "        })\n",
    "        std_row.update({\n",
    "            'mean_std': np.std(metrics['std']),\n",
    "            'mean_ci_width': np.std(metrics['ci_width'])\n",
    "        })\n",
    "\n",
    "    csv_data.append(summary_row)\n",
    "    csv_data.append(std_row)\n",
    "\n",
    "    # Save as CSV\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    csv_path = f\"results/cross_validation/{model_class.__name__}_{n_splits}fold_cv_results.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Cross-validation results saved to: {csv_path}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ----------------------\n",
    "# 6. Modified Training Framework\n",
    "# ----------------------\n",
    "def train_final_model(model_class, X_train_val, y_train_val, lr=0.001):\n",
    "    \"\"\"Train the final model using all training data\"\"\"\n",
    "    # Standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_train_val)\n",
    "\n",
    "    # Convert to tensors and move to GPU\n",
    "    X_t = torch.FloatTensor(X_scaled).to(device)\n",
    "    y_t = torch.FloatTensor(y_train_val).unsqueeze(1).to(device)\n",
    "\n",
    "    # Initialize model and move to GPU\n",
    "    model = model_class(X_scaled.shape[1]).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Training (use all data, no early stopping)\n",
    "    for epoch in range(1500):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_t)\n",
    "        loss = criterion(outputs, y_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Save the model (move to CPU before saving)\n",
    "    model.to(\"cpu\")  # Move to CPU before saving\n",
    "    torch.save({\n",
    "        'model_state': model.state_dict(),\n",
    "        'scaler': scaler  # Save the scaler\n",
    "    }, f'FINAL_{model_class.__name__}.pth')\n",
    "\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    # Move the model to the same device as test data\n",
    "    model = model.to(device)\n",
    "\n",
    "    X_test_scaled = scaler.transform(X_test)  # Assume X_test is a global variable\n",
    "    X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Move training data to the same device as the model\n",
    "        X_scaled_tensor = torch.FloatTensor(X_scaled).to(device)\n",
    "        y_pred_train = model(X_scaled_tensor).cpu().numpy().flatten()  # Training set predictions\n",
    "        y_pred_test = model(X_test_tensor).cpu().numpy().flatten()  # Test set predictions\n",
    "\n",
    "    # Save training set results (optional)\n",
    "    train_results = pd.DataFrame({\n",
    "        'actual_value': y_train_val,\n",
    "        'predicted_value': y_pred_train\n",
    "    })\n",
    "    train_csv_path = f\"results/train_predictions/{model_class.__name__}_train_results.csv\"\n",
    "    os.makedirs(os.path.dirname(train_csv_path), exist_ok=True)\n",
    "    train_results.to_csv(train_csv_path, index=False)\n",
    "    print(f\"Training set predictions saved to: {train_csv_path}\")\n",
    "\n",
    "    # Save test set results\n",
    "    test_results = pd.DataFrame({\n",
    "        'actual_value': y_test,\n",
    "        'predicted_value': y_pred_test\n",
    "    })\n",
    "    test_csv_path = f\"results/test_predictions/{model_class.__name__}_test_results.csv\"\n",
    "    os.makedirs(os.path.dirname(test_csv_path), exist_ok=True)\n",
    "    test_results.to_csv(test_csv_path, index=False)\n",
    "    print(f\"Test set predictions saved to: {test_csv_path}\")\n",
    "\n",
    "    return model.to(device)  # Return moved back to GPU\n",
    "\n",
    "# ----------------------\n",
    "# 7. External Validation Set Evaluation\n",
    "# ----------------------\n",
    "def evaluate_on_external_set(model, X_ext, y_ext, model_name, casNumber, monte_carlo=True):\n",
    "    \"\"\"\n",
    "    Evaluate model performance on external validation set and save results as CSV\n",
    "\n",
    "    Args:\n",
    "    - model: Trained PyTorch model\n",
    "    - X_ext: External validation features\n",
    "    - y_ext: External validation targets\n",
    "    - model_name: Model name\n",
    "    - monte_carlo: Whether to use Monte Carlo dropout for uncertainty estimation\n",
    "\n",
    "    Returns:\n",
    "    - metrics: Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    X_tensor = torch.FloatTensor(X_ext).to(device)\n",
    "\n",
    "    # Basic prediction\n",
    "    with torch.no_grad():\n",
    "        preds = model(X_tensor).cpu().numpy().flatten()\n",
    "\n",
    "    # Calculate basic metrics\n",
    "    r2 = r2_score(y_ext, preds)\n",
    "    mae = mean_absolute_error(y_ext, preds)\n",
    "    mse = mean_squared_error(y_ext, preds)\n",
    "\n",
    "    metrics = {\n",
    "        'r2': r2,\n",
    "        'mae': mae,\n",
    "        'mse': mse\n",
    "    }\n",
    "\n",
    "    print(f\"\\n📋 External Validation Set Results:\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "\n",
    "    # Prepare CSV data\n",
    "    csv_data = [{\n",
    "        'r2': r2,\n",
    "        'mae': mae,\n",
    "        'mse': mse\n",
    "    }]\n",
    "\n",
    "    # Monte Carlo uncertainty estimation\n",
    "    if monte_carlo:\n",
    "        mean_pred, std_pred, ci_lower, ci_upper, all_preds = monte_carlo_prediction(model, X_ext)\n",
    "\n",
    "        mean_std = np.mean(std_pred)\n",
    "        mean_ci_width = np.mean(ci_upper - ci_lower)\n",
    "\n",
    "        metrics.update({\n",
    "            'mean_pred': mean_pred,\n",
    "            'std_pred': std_pred,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'mean_std': mean_std,\n",
    "            'mean_ci_width': mean_ci_width\n",
    "        })\n",
    "\n",
    "        # Update CSV data\n",
    "        csv_data[0].update({\n",
    "            'mean_std': mean_std,\n",
    "            'mean_ci_width': mean_ci_width,\n",
    "            'mean_ci_lower': np.mean(ci_lower),\n",
    "            'mean_ci_upper': np.mean(ci_upper)\n",
    "        })\n",
    "\n",
    "        print(f\"\\n📊 Monte Carlo Uncertainty Estimation on External Set:\")\n",
    "        print(f\"Average Standard Deviation: {mean_std:.4f}\")\n",
    "        print(f\"Average 95% Confidence Interval Width: {mean_ci_width:.4f}\")\n",
    "        print(f\"Mean CI Lower Bound: {np.mean(ci_lower):.4f}\")\n",
    "        print(f\"Mean CI Upper Bound: {np.mean(ci_upper):.4f}\")\n",
    "\n",
    "        # Save detailed Monte Carlo statistics\n",
    "        mc_data = []\n",
    "        for i in range(len(y_ext)):\n",
    "            mc_data.append({\n",
    "                'sample_id': i,\n",
    "                'true_value': y_ext[i],\n",
    "                'mean_pred': mean_pred[i],\n",
    "                'std': std_pred[i],\n",
    "                'ci_lower': ci_lower[i],\n",
    "                'ci_upper': ci_upper[i]\n",
    "            })\n",
    "\n",
    "        mc_df = pd.DataFrame(mc_data)\n",
    "        mc_csv_path = f\"results/monte_carlo/{model_name}_monte_carlo_stats.csv\"\n",
    "        mc_df.to_csv(mc_csv_path, index=False)\n",
    "        print(f\"Monte Carlo statistics saved to: {mc_csv_path}\")\n",
    "\n",
    "    # Save external validation results\n",
    "    ext_df = pd.DataFrame(csv_data)\n",
    "    ext_csv_path = f\"results/external_validation/{model_name}_external_validation.csv\"\n",
    "    ext_df.to_csv(ext_csv_path, index=False)\n",
    "    print(f\"External validation results saved to: {ext_csv_path}\")\n",
    "\n",
    "    # Save detailed actual vs predicted values\n",
    "    ext_detail_data = pd.DataFrame({\n",
    "        'cas': casNumber,\n",
    "        'actual_value': y_ext,\n",
    "        'predicted_value': preds\n",
    "    })\n",
    "\n",
    "    # Add Monte Carlo prediction intervals (optional)\n",
    "    if monte_carlo:\n",
    "        ext_detail_data['mean_pred'] = metrics['mean_pred']\n",
    "        ext_detail_data['ci_lower'] = metrics['ci_lower']\n",
    "        ext_detail_data['ci_upper'] = metrics['ci_upper']\n",
    "\n",
    "    ext_detail_csv_path = f\"results/external_validation/{model_name}_external_detail.csv\"\n",
    "    ext_detail_data.to_csv(ext_detail_csv_path, index=False)\n",
    "    print(f\"Detailed external validation results (actual vs predicted) saved to: {ext_detail_csv_path}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# ----------------------\n",
    "# 8. Main Function: Run All Models\n",
    "# ----------------------\n",
    "def run_all_models():\n",
    "    \"\"\"Run training, validation, and evaluation for all models, and save results as CSV\"\"\"\n",
    "    # Create results directories\n",
    "    create_results_directories()\n",
    "\n",
    "    # Load external validation set\n",
    "    X_ext, y_ext, casNumber = load_external_validation_set()\n",
    "\n",
    "    if X_ext is None or y_ext is None:\n",
    "        print(\"Unable to load external validation set, skipping external validation evaluation\")\n",
    "\n",
    "    # List of models\n",
    "    models = [MLP, MLP_Attention, CNNModel, CNN_Attention, AttentionModel]\n",
    "    model_names = [\"MLP\", \"MLP_Attention\", \"CNN\", \"CNN_Attention\", \"Attention\"]\n",
    "\n",
    "    # Results storage\n",
    "    results = {\n",
    "        '5-fold': {},\n",
    "        '10-fold': {},\n",
    "        'external': {}\n",
    "    }\n",
    "\n",
    "    # Prepare comparison data\n",
    "    comparison_data = []\n",
    "\n",
    "    # Perform 5-fold and 10-fold validation for each model\n",
    "    for model_class, model_name in zip(models, model_names):\n",
    "        print(f\"\\n{'#'*100}\")\n",
    "        print(f\"Processing Model: {model_name}\")\n",
    "        print(f\"{'#'*100}\")\n",
    "\n",
    "        # 5-fold cross-validation\n",
    "        print(\"\\n🔄 Running 5-fold Cross Validation...\")\n",
    "        results['5-fold'][model_name] = kfold_validate(model_class, X_train_val, y_train_val, n_splits=5)\n",
    "\n",
    "        # 10-fold cross-validation\n",
    "        print(\"\\n🔄 Running 10-fold Cross Validation...\")\n",
    "        results['10-fold'][model_name] = kfold_validate(model_class, X_train_val, y_train_val, n_splits=10)\n",
    "\n",
    "        # Train final model\n",
    "        print(\"\\n🏆 Training Final Model...\")\n",
    "        final_model = train_final_model(model_class, X_train_val, y_train_val)\n",
    "\n",
    "        # Evaluate on external validation set (if available)\n",
    "        if X_ext is not None and y_ext is not None:\n",
    "            print(\"\\n🔍 Evaluating on External Validation Set...\")\n",
    "            results['external'][model_name] = evaluate_on_external_set(final_model, X_ext, y_ext, model_name, casNumber)\n",
    "\n",
    "        # Add to comparison data\n",
    "        # 5-fold results\n",
    "        fold5_row = {\n",
    "            'model_name': model_name,\n",
    "            'fold_type': '5-fold',\n",
    "            'r2_mean': np.mean(results['5-fold'][model_name]['r2']),\n",
    "            'r2_std': np.std(results['5-fold'][model_name]['r2']),\n",
    "            'mae_mean': np.mean(results['5-fold'][model_name]['mae']),\n",
    "            'mae_std': np.std(results['5-fold'][model_name]['mae']),\n",
    "            'mse_mean': np.mean(results['5-fold'][model_name]['mse']),\n",
    "            'mse_std': np.std(results['5-fold'][model_name]['mse'])\n",
    "        }\n",
    "\n",
    "        # 10-fold results\n",
    "        fold10_row = {\n",
    "            'model_name': model_name,\n",
    "            'fold_type': '10-fold',\n",
    "            'r2_mean': np.mean(results['10-fold'][model_name]['r2']),\n",
    "            'r2_std': np.std(results['10-fold'][model_name]['r2']),\n",
    "            'mae_mean': np.mean(results['10-fold'][model_name]['mae']),\n",
    "            'mae_std': np.std(results['10-fold'][model_name]['mae']),\n",
    "            'mse_mean': np.mean(results['10-fold'][model_name]['mse']),\n",
    "            'mse_std': np.std(results['10-fold'][model_name]['mse'])\n",
    "        }\n",
    "\n",
    "        # Add Monte Carlo statistics (if available)\n",
    "        if 'std' in results['5-fold'][model_name]:\n",
    "            fold5_row.update({\n",
    "                'mc_std': np.mean(results['5-fold'][model_name]['std']),\n",
    "                'mc_ci_width': np.mean(results['5-fold'][model_name]['ci_width'])\n",
    "            })\n",
    "            fold10_row.update({\n",
    "                'mc_std': np.mean(results['10-fold'][model_name]['std']),\n",
    "                'mc_ci_width': np.mean(results['10-fold'][model_name]['ci_width'])\n",
    "            })\n",
    "\n",
    "        comparison_data.append(fold5_row)\n",
    "        comparison_data.append(fold10_row)\n",
    "\n",
    "    # Save comparison results\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    comparison_csv_path = \"results/comparison/model_comparison.csv\"\n",
    "    comparison_df.to_csv(comparison_csv_path, index=False)\n",
    "    print(f\"Model comparison results saved to: {comparison_csv_path}\")\n",
    "\n",
    "    # Print comparison results\n",
    "    print(\"\\n📊 Comparison of 5-fold and 10-fold Cross Validation Results:\")\n",
    "    for model_name in model_names:\n",
    "        print(f\"\\n{'-'*50}\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"{'-'*50}\")\n",
    "\n",
    "        print(f\"5-fold R²: {np.mean(results['5-fold'][model_name]['r2']):.4f} ± {np.std(results['5-fold'][model_name]['r2']):.4f}\")\n",
    "        print(f\"10-fold R²: {np.mean(results['10-fold'][model_name]['r2']):.4f} ± {np.std(results['10-fold'][model_name]['r2']):.4f}\")\n",
    "\n",
    "        print(f\"5-fold MAE: {np.mean(results['5-fold'][model_name]['mae']):.4f} ± {np.std(results['5-fold'][model_name]['mae']):.4f}\")\n",
    "        print(f\"10-fold MAE: {np.mean(results['10-fold'][model_name]['mae']):.4f} ± {np.std(results['10-fold'][model_name]['mae']):.4f}\")\n",
    "\n",
    "        print(f\"5-fold MSE: {np.mean(results['5-fold'][model_name]['mse']):.4f} ± {np.std(results['5-fold'][model_name]['mse']):.4f}\")\n",
    "        print(f\"10-fold MSE: {np.mean(results['10-fold'][model_name]['mse']):.4f} ± {np.std(results['10-fold'][model_name]['mse']):.4f}\")\n",
    "\n",
    "        if 'std' in results['5-fold'][model_name]:\n",
    "            print(f\"5-fold Average Standard Deviation: {np.mean(results['5-fold'][model_name]['std']):.4f}\")\n",
    "            print(f\"10-fold Average Standard Deviation: {np.mean(results['10-fold'][model_name]['std']):.4f}\")\n",
    "\n",
    "            print(f\"5-fold Average 95% Confidence Interval Width: {np.mean(results['5-fold'][model_name]['ci_width']):.4f}\")\n",
    "            print(f\"10-fold Average 95% Confidence Interval Width: {np.mean(results['10-fold'][model_name]['ci_width']):.4f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# If this script is run directly, execute training and evaluation for all models\n",
    "if __name__ == \"__main__\":\n",
    "    run_all_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
